<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Building a basic kubernetes cluster with kubeadm - ideas</title><meta name=description content="This is just a basic setup installing a 3 node Kubernetes setup on 3 nodes. The nodes can probably be anywhere, AWS, GCP, VMware etc as long as they are running Ubuntu 20.04.
One node needs to be designated as the master and the other 2 as workers.
To start with the pre-requisites need to be installed on all 3 nodes. This can be done via a script or by entering the commands below individually"><meta name=author content="Neil Armitage"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"ideas","url":"https:\/\/neilarmitage.com\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"https:\/\/neilarmitage.com\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https:\/\/neilarmitage.com\/","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"https:\/\/neilarmitage.com\/posts\/basic_kubernetes_cluster\/","name":"Building a basic kubernetes cluster with kubeadm"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":"Neil Armitage"},"headline":"Building a basic kubernetes cluster with kubeadm","description":"This is just a basic setup installing a 3 node Kubernetes setup on 3 nodes. The nodes can probably be anywhere, AWS, GCP, VMware etc as long as they are running Ubuntu 20.04.\nOne node needs to be designated as the master and the other 2 as workers.\nTo start with the pre-requisites need to be installed on all 3 nodes. This can be done via a script or by entering the commands below individually","inLanguage":"en","wordCount":420,"datePublished":"2022-12-09T14:07:31","dateModified":"2022-12-09T14:07:31","image":"https:\/\/neilarmitage.com\/images\/monkey.gif","keywords":["kubernetes"],"mainEntityOfPage":"https:\/\/neilarmitage.com\/posts\/basic_kubernetes_cluster\/","publisher":{"@type":"Organization","name":"https:\/\/neilarmitage.com\/","logo":{"@type":"ImageObject","url":"https:\/\/neilarmitage.com\/images\/monkey.gif","height":60,"width":60}}}</script><meta property="og:title" content="Building a basic kubernetes cluster with kubeadm"><meta property="og:description" content="This is just a basic setup installing a 3 node Kubernetes setup on 3 nodes. The nodes can probably be anywhere, AWS, GCP, VMware etc as long as they are running Ubuntu 20.04.
One node needs to be designated as the master and the other 2 as workers.
To start with the pre-requisites need to be installed on all 3 nodes. This can be done via a script or by entering the commands below individually"><meta property="og:image" content="https://neilarmitage.com/images/monkey.gif"><meta property="og:url" content="https://neilarmitage.com/posts/basic_kubernetes_cluster/"><meta property="og:type" content="website"><meta property="og:site_name" content="ideas"><meta name=twitter:title content="Building a basic kubernetes cluster with kubeadm"><meta name=twitter:description content="This is just a basic setup installing a 3 node Kubernetes setup on 3 nodes. The nodes can probably be anywhere, AWS, GCP, VMware etc as long as they are running Ubuntu 20.04.
One node needs to be â€¦"><meta name=twitter:image content="https://neilarmitage.com/images/monkey.gif"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@narmitage"><meta name=twitter:creator content="@narmitage"><meta name=generator content="Hugo 0.108.0"><link rel=alternate href=https://neilarmitage.com/index.xml type=application/rss+xml title=ideas><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.5.0/css/all.css integrity=sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU crossorigin=anonymous><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link rel=stylesheet href=https://neilarmitage.com/css/main.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800"><link rel=stylesheet href=https://neilarmitage.com/css/highlight.min.css><link rel=stylesheet href=https://neilarmitage.com/css/codeblock.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css integrity=sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css integrity=sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R crossorigin=anonymous></head><body><nav class="navbar navbar-default navbar-fixed-top navbar-custom"><div class=container-fluid><div class=navbar-header><button type=button class=navbar-toggle data-toggle=collapse data-target=#main-navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class=navbar-brand href=https://neilarmitage.com/>ideas</a></div><div class="collapse navbar-collapse" id=main-navbar><ul class="nav navbar-nav navbar-right"><li><a title=about href=/about/>about</a></li><li><a title=talks href=https://speakerdeck.com/neilarmitage>talks</a></li></ul></div><div class=avatar-container><div class=avatar-img-border><a title=ideas href=https://neilarmitage.com/><img class=avatar-img src=https://neilarmitage.com/images/monkey.gif alt=ideas></a></div></div></div></nav><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header class=header-section><div class="intro-header no-img"><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=posts-heading><h1>Building a basic kubernetes cluster with kubeadm</h1><hr class=small></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><article role=main class=blog-post><p><img src=/images/k8s-3node.png alt="Image alt"></p><p>This is just a basic setup installing a 3 node Kubernetes setup on 3 nodes. The nodes can probably be anywhere, AWS, GCP, VMware etc as long as they are running Ubuntu 20.04.</p><p>One node needs to be designated as the master and the other 2 as workers.</p><p>To start with the pre-requisites need to be installed on all 3 nodes. This can be done via a script or by entering the commands below individually</p><p>Download and run the script</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl https://raw.githubusercontent.com/narmitag/kubernetes/main/basic_setup/setup_machine.sh -o setup_machine.sh
</span></span><span class=line><span class=cl>chmod +x setup_machine.sh
</span></span><span class=line><span class=cl>sudo ./setup_machine.sh
</span></span></code></pre></div><p>Running the steps:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1>#Install containerd</span>
</span></span><span class=line><span class=cl>cat <span class=s>&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf 
</span></span></span><span class=line><span class=cl><span class=s>overlay 
</span></span></span><span class=line><span class=cl><span class=s>br_netfilter 
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl>sudo modprobe overlay 
</span></span><span class=line><span class=cl>sudo modprobe br_netfilter
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>cat <span class=s>&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf 
</span></span></span><span class=line><span class=cl><span class=s>net.bridge.bridge-nf-call-iptables = 1 
</span></span></span><span class=line><span class=cl><span class=s>net.ipv4.ip_forward = 1 
</span></span></span><span class=line><span class=cl><span class=s>net.bridge.bridge-nf-call-ip6tables = 1 
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>sudo sysctl --system
</span></span><span class=line><span class=cl>sudo apt-get update <span class=o>&amp;&amp;</span> sudo apt-get install -y containerd
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>sudo mkdir -p /etc/containerd
</span></span><span class=line><span class=cl>sudo containerd config default <span class=p>|</span> sudo tee /etc/containerd/config.toml
</span></span><span class=line><span class=cl>sudo systemctl restart containerd
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#Disable swap </span>
</span></span><span class=line><span class=cl>sudo swapoff -a
</span></span><span class=line><span class=cl>sudo sed -e <span class=s1>&#39;/swap/ s/^#*/#/&#39;</span> -i /etc/fstab   
</span></span><span class=line><span class=cl>curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg <span class=p>|</span> sudo apt-key add -
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#Install Kubernetes binaries</span>
</span></span><span class=line><span class=cl>cat <span class=s>&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
</span></span></span><span class=line><span class=cl><span class=s>deb https://apt.kubernetes.io/ kubernetes-xenial main
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install -y <span class=nv>kubelet</span><span class=o>=</span>1.24.0-00 <span class=nv>kubeadm</span><span class=o>=</span>1.24.0-00 <span class=nv>kubectl</span><span class=o>=</span>1.24.0-00
</span></span><span class=line><span class=cl>sudo apt-mark hold kubelet kubeadm kubectl
</span></span></code></pre></div><p>The cluster now needs to be bootstrapped from the master</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ sudo  kubeadm init --pod-network-cidr 192.168.0.0/16 --kubernetes-version 1.24.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>$ mkdir -p <span class=nv>$HOME</span>/.kube 
</span></span><span class=line><span class=cl>$ sudo cp -i /etc/kubernetes/admin.conf <span class=nv>$HOME</span>/.kube/config 
</span></span><span class=line><span class=cl>$ sudo chown <span class=k>$(</span>id -u<span class=k>)</span>:<span class=k>$(</span>id -g<span class=k>)</span> <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>$ kubectl get no
</span></span><span class=line><span class=cl>NAME   STATUS     ROLES           AGE   VERSION
</span></span><span class=line><span class=cl>master   NotReady   control-plane   50s   v1.24.0
</span></span></code></pre></div><p>A network plugin needs to be installed to get the node ready (it may take a few minutes for the node to become ready). This will install <a href=https://projectcalico.docs.tigera.io/getting-started/kubernetes/>calico</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>poddisruptionbudget.policy/calico-kube-controllers created
</span></span><span class=line><span class=cl>serviceaccount/calico-kube-controllers created
</span></span><span class=line><span class=cl>serviceaccount/calico-node created
</span></span><span class=line><span class=cl>configmap/calico-config created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/caliconodestatuses.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/ipreservations.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created
</span></span><span class=line><span class=cl>customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created
</span></span><span class=line><span class=cl>clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created
</span></span><span class=line><span class=cl>clusterrole.rbac.authorization.k8s.io/calico-node created
</span></span><span class=line><span class=cl>clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created
</span></span><span class=line><span class=cl>clusterrolebinding.rbac.authorization.k8s.io/calico-node created
</span></span><span class=line><span class=cl>daemonset.apps/calico-node created
</span></span><span class=line><span class=cl>deployment.apps/calico-kube-controllers created
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>$ kubectl get no
</span></span><span class=line><span class=cl>NAME   STATUS   ROLES           AGE   VERSION
</span></span><span class=line><span class=cl>master   Ready    control-plane   87s   v1.24.0
</span></span></code></pre></div><p>The workers can now be connected, so get kubeadm to generate the required command on the master.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ kubeadm token create --print-join-command
</span></span></code></pre></div><p>The run the command generated above on each worker</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ sudo kubeadmin join ............
</span></span></code></pre></div><p>The master should now show 3 nodes</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>
</span></span><span class=line><span class=cl>$ kubectl get no
</span></span><span class=line><span class=cl>NAME   STATUS   ROLES           AGE   VERSION
</span></span><span class=line><span class=cl>master   Ready    control-plane   120s  v1.24.0
</span></span><span class=line><span class=cl>worker-1 Ready    &lt;none&gt;          77s   v1.24.0
</span></span><span class=line><span class=cl>worker-2 Ready    &lt;none&gt;          97s   v1.24.0
</span></span></code></pre></div><div class=blog-tags><a href=https://neilarmitage.com//tags/kubernetes/>kubernetes</a>&nbsp;</div><hr><section id=social-share><div class="list-inline footer-links"><div class=share-box aria-hidden=true><ul class=share><li><a href="//twitter.com/share?url=https%3a%2f%2fneilarmitage.com%2fposts%2fbasic_kubernetes_cluster%2f&text=Building%20a%20basic%20kubernetes%20cluster%20with%20kubeadm&via=narmitage" target=_blank title="Share on Twitter"><i class="fab fa-twitter"></i></a></li><li><a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fneilarmitage.com%2fposts%2fbasic_kubernetes_cluster%2f" target=_blank title="Share on Facebook"><i class="fab fa-facebook"></i></a></li><li><a href="//reddit.com/submit?url=https%3a%2f%2fneilarmitage.com%2fposts%2fbasic_kubernetes_cluster%2f&title=Building%20a%20basic%20kubernetes%20cluster%20with%20kubeadm" target=_blank title="Share on Reddit"><i class="fab fa-reddit"></i></a></li><li><a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fneilarmitage.com%2fposts%2fbasic_kubernetes_cluster%2f&title=Building%20a%20basic%20kubernetes%20cluster%20with%20kubeadm" target=_blank title="Share on LinkedIn"><i class="fab fa-linkedin"></i></a></li><li><a href="//www.stumbleupon.com/submit?url=https%3a%2f%2fneilarmitage.com%2fposts%2fbasic_kubernetes_cluster%2f&title=Building%20a%20basic%20kubernetes%20cluster%20with%20kubeadm" target=_blank title="Share on StumbleUpon"><i class="fab fa-stumbleupon"></i></a></li><li><a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fneilarmitage.com%2fposts%2fbasic_kubernetes_cluster%2f&description=Building%20a%20basic%20kubernetes%20cluster%20with%20kubeadm" target=_blank title="Share on Pinterest"><i class="fab fa-pinterest"></i></a></li></ul></div></div></section><h4 class=see-also>See also</h4><ul><li><a href=/posts/upgrade_kubernetes/>Upgrade Kubernetes to 1.26</a></li><li><a href=/posts/upgrade_containerd/>Upgrade Containerd on Ubuntu 20.04</a></li></ul></article><ul class="pager blog-pager"><li class=previous><a href=https://neilarmitage.com/posts/bastion_using_ssm/ data-toggle=tooltip data-placement=top title="SSM Bastion with no NAT Gateway">&larr; Previous Post</a></li><li class=next><a href=https://neilarmitage.com/posts/upgrade_containerd/ data-toggle=tooltip data-placement=top title="Upgrade Containerd on Ubuntu 20.04">Next Post &rarr;</a></li></ul></div></div></div><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href=mailto:neil@neilarmitage.com title="Email me"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a href=https://github.com/narmitag title=GitHub><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a href=https://twitter.com/narmitage title=Twitter><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-twitter fa-stack-1x fa-inverse"></i></span></a></li><li><a href=https://linkedin.com/in/neil-a-5750885 title=LinkedIn><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-linkedin fa-stack-1x fa-inverse"></i></span></a></li><li><a href title=RSS><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="credits copyright text-muted"><a href=neilarmitage.com>Neil Armitage</a>
&nbsp;&bull;&nbsp;&copy;
2022
&nbsp;&bull;&nbsp;
<a href=https://neilarmitage.com/>ideas</a></p><p class="credits theme-by text-muted"><a href=https://gohugo.io>Hugo v0.108.0</a> powered &nbsp;&bull;&nbsp; Theme <a href=https://github.com/halogenica/beautifulhugo>Beautiful Hugo</a> adapted from <a href=https://deanattali.com/beautiful-jekyll/>Beautiful Jekyll</a>
&nbsp;&bull;&nbsp;[<a href=https://github.com/narmitag/narmitag.github.io/e5ffff34d44886a913d70f9001fe8b548d49ba46>e5ffff34</a>]</p></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous></script>
<script src=https://code.jquery.com/jquery-3.5.1.slim.min.js integrity=sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj crossorigin=anonymous></script>
<script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script>
<script src=https://neilarmitage.com/js/main.js></script>
<script src=https://neilarmitage.com/js/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><script>$(document).ready(function(){$("pre.chroma").css("padding","0")})</script><script>renderMathInElement(document.body)</script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js integrity=sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js integrity=sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q crossorigin=anonymous></script><script src=https://neilarmitage.com/js/load-photoswipe.js></script></body></html>