<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AWS EKS on Random Stuff From My Head</title>
    <link>https://neilarmitage.com/categories/aws-eks/</link>
    <description>Recent content in AWS EKS on Random Stuff From My Head</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>neil@neilarmitage.com (Neil Armitage)</managingEditor>
    <webMaster>neil@neilarmitage.com (Neil Armitage)</webMaster>
    <lastBuildDate>Thu, 12 May 2022 08:11:08 +0000</lastBuildDate><atom:link href="https://neilarmitage.com/categories/aws-eks/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Installing Karpenter</title>
      <link>https://neilarmitage.com/posts/karpenter/</link>
      <pubDate>Thu, 12 May 2022 08:11:08 +0000</pubDate>
      <author>neil@neilarmitage.com (Neil Armitage)</author>
      <guid>https://neilarmitage.com/posts/karpenter/</guid>
      <description>Karpenter automatically launches just the right compute resources to handle your cluster&amp;rsquo;s applications. It is designed to let you take full advantage of the cloud with fast and simple compute provisioning for Kubernetes clusters. It is a replacement for the Cluster Autoscaler which has some issues in AWS
This at the moment this example does not work on an acloudguru sandbox account. The supporting files can be found on Github</description>
    </item>
    
    <item>
      <title>Basic EKS Cluster with Cluster Autoscaler</title>
      <link>https://neilarmitage.com/posts/basic-eks-cluster/</link>
      <pubDate>Wed, 11 May 2022 10:38:08 +0000</pubDate>
      <author>neil@neilarmitage.com (Neil Armitage)</author>
      <guid>https://neilarmitage.com/posts/basic-eks-cluster/</guid>
      <description>EKSCTL can be used to quickly deploy a AWS EKS Cluster.
This is based on using a sandbox AWS account The supporting files can be found on Github
Create an EKS deployment file, I tend to create individual nodegroups dedicated to a single AZ
[cloudshell-user@ip-10-1-181-252 cluster-autoscaler]$ cat ca-cluster.yaml --- apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: ca-cluster --- apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: ca-cluster region: us-east-1 version: &amp;#34;1.22&amp;#34; availabilityZones: [&amp;#34;us-east-1a&amp;#34;, &amp;#34;us-east-1b&amp;#34;, &amp;#34;us-east-1c&amp;#34;] managedNodeGroups: - name: nodegroupA desiredCapacity: 1 availabilityZones: [&amp;#34;us-east-1a&amp;#34;] instanceType: t3.</description>
    </item>
    
    <item>
      <title>EKS with Cilium in chaining mode</title>
      <link>https://neilarmitage.com/posts/cilium-chaining/</link>
      <pubDate>Wed, 11 May 2022 10:38:08 +0000</pubDate>
      <author>neil@neilarmitage.com (Neil Armitage)</author>
      <guid>https://neilarmitage.com/posts/cilium-chaining/</guid>
      <description>Cilium can run in chaining mode which allows it to run alongside the AWS-CNI plugin.
This is based on using a sandbox AWS account The supporting files can be found on Github
Install some extra tools
curl -L --remote-name-all https://github.com/cilium/cilium-cli/releases/latest/download/cilium-linux-amd64.tar.gz{,.sha256sum} sha256sum --check cilium-linux-amd64.tar.gz.sha256sum sudo tar xzvfC cilium-linux-amd64.tar.gz /usr/local/bin rm cilium-linux-amd64.tar.gz{,.sha256sum} export HUBBLE_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/hubble/master/stable.txt) curl -L --remote-name-all https://github.com/cilium/hubble/releases/download/$HUBBLE_VERSION/hubble-linux-amd64.tar.gz{,.sha256sum} sha256sum --check hubble-linux-amd64.tar.gz.sha256sum sudo tar xzvfC hubble-linux-amd64.tar.gz /usr/local/bin rm hubble-linux-amd64.tar.gz{,.sha256sum} Deploy an EKS Cluster</description>
    </item>
    
  </channel>
</rss>
